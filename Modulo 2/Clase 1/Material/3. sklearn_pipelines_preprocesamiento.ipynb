{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de Scikit-learn para Construir Pipelines de Preprocesamiento üõ†Ô∏èüîó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducci√≥n\n",
    "\n",
    "En las clases anteriores, vimos c√≥mo aplicar individualmente diversas t√©cnicas de limpieza y transformaci√≥n de datos. Si bien esto es √∫til para entender cada paso, en la pr√°ctica, aplicar m√∫ltiples transformaciones secuencialmente puede volverse tedioso, propenso a errores y dif√≠cil de gestionar, especialmente cuando se trabaja con conjuntos de datos de entrenamiento y prueba.\n",
    "\n",
    "Scikit-learn ofrece una herramienta poderosa para encadenar m√∫ltiples pasos de preprocesamiento (y modelado): los **Pipelines**. Un `Pipeline` permite ensamblar varias transformaciones y, opcionalmente, un estimador final (como un modelo de clasificaci√≥n o regresi√≥n) en un √∫nico objeto.\n",
    "\n",
    "Adem√°s, para aplicar diferentes transformaciones a diferentes columnas de nuestro dataset (por ejemplo, escalar columnas num√©ricas y codificar columnas categ√≥ricas), usaremos `ColumnTransformer`.\n",
    "\n",
    "**Ventajas de usar Pipelines y ColumnTransformer:**\n",
    "* **Simplicidad y Claridad:** El c√≥digo se vuelve m√°s organizado y legible.\n",
    "* **Consistencia:** Asegura que los mismos pasos de preprocesamiento se apliquen de manera id√©ntica a diferentes conjuntos de datos (ej. entrenamiento y prueba).\n",
    "* **Prevenci√≥n de Fuga de Datos (Data Leakage):** Ayuda a aplicar correctamente `fit` solo en los datos de entrenamiento y `transform` tanto en entrenamiento como en prueba.\n",
    "* **Facilidad de Experimentaci√≥n:** Permite cambiar o ajustar pasos del preprocesamiento f√°cilmente.\n",
    "* **Preparaci√≥n para Despliegue:** Un pipeline completo puede ser guardado y cargado para usarse en producci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configuraci√≥n e Importaci√≥n de Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Para Pipelines y ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Para Imputaci√≥n\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Para Escalado y Codificaci√≥n\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Para dividir el dataset (aunque en este notebook nos enfocaremos en el preprocesador)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuraci√≥n para mostrar todas las columnas\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carga del Dataset (Titanic)\n",
    "\n",
    "Cargaremos la versi√≥n \"cruda\" del dataset del Titanic para demostrar c√≥mo un pipeline puede manejar varias tareas de preprocesamiento a la vez. En un flujo de trabajo de Machine Learning real, dividir√≠amos los datos en conjuntos de entrenamiento y prueba ANTES de ajustar cualquier transformador para evitar la fuga de datos. Para esta demostraci√≥n del pipeline de preprocesamiento, nos centraremos en construir el preprocesador, pero es crucial recordar este orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset del Titanic (raw) cargado.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informaci√≥n inicial del dataset raw:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "\n",
      "Forma de X: (891, 14), Forma de y: (891,)\n"
     ]
    }
   ],
   "source": [
    "url_titanic = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "try:\n",
    "    df_titanic_raw = pd.read_csv(url_titanic)\n",
    "    print(\"Dataset del Titanic (raw) cargado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar: {e}\")\n",
    "    df_titanic_raw = pd.DataFrame() # DataFrame vac√≠o para evitar errores posteriores\n",
    "\n",
    "if not df_titanic_raw.empty:\n",
    "    display(df_titanic_raw.head())\n",
    "    print(\"Informaci√≥n inicial del dataset raw:\")\n",
    "    df_titanic_raw.info()\n",
    "    \n",
    "    # Separaremos caracter√≠sticas (X) y variable objetivo (y) para simular un escenario de ML\n",
    "    # 'survived' es nuestra variable objetivo. El resto (o un subconjunto) son caracter√≠sticas.\n",
    "    if 'survived' in df_titanic_raw.columns:\n",
    "        X = df_titanic_raw.drop('survived', axis=1)\n",
    "        y = df_titanic_raw['survived']\n",
    "        print(f\"\\nForma de X: {X.shape}, Forma de y: {y.shape}\")\n",
    "    else:\n",
    "        print(\"Advertencia: La columna 'survived' no se encuentra. Se usar√° todo el DataFrame como X.\")\n",
    "        X = df_titanic_raw.copy()\n",
    "        y = None\n",
    "else:\n",
    "    X = pd.DataFrame() # DataFrame vac√≠o\n",
    "    y = pd.Series(dtype='float64') if pd.Series is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota Importante sobre `fit` y `transform`:**\n",
    "En un flujo de trabajo de Machine Learning real:\n",
    "1.  Dividir√≠as `X` e `y` en `X_train`, `X_test`, `y_train`, `y_test`.\n",
    "2.  Ajustar√≠as (`fit`) el pipeline de preprocesamiento **√∫nicamente** en `X_train`.\n",
    "3.  Aplicar√≠as la transformaci√≥n (`transform`) tanto a `X_train` como a `X_test`.\n",
    "Para simplificar esta demostraci√≥n del pipeline en s√≠, podr√≠amos ajustar el preprocesador en todo `X`, pero ten en mente que esto no es lo que har√≠as antes de entrenar un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definici√≥n de Transformadores y Pipelines por Tipo de Columna\n",
    "\n",
    "Primero, identificamos qu√© columnas son num√©ricas y cu√°les son categ√≥ricas. Luego, definimos las transformaciones que queremos aplicar a cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas num√©ricas a procesar: ['age', 'fare', 'sibsp', 'parch', 'pclass']\n",
      "Columnas categ√≥ricas (para OneHot) a procesar: ['sex', 'embarked']\n"
     ]
    }
   ],
   "source": [
    "if not X.empty:\n",
    "    # Identificar columnas num√©ricas y categ√≥ricas\n",
    "    # (Excluimos columnas que podr√≠amos querer dropear directamente o tratar de forma especial como 'name', 'ticket', 'cabin')\n",
    "    cols_numericas = ['age', 'fare', 'sibsp', 'parch', 'pclass'] # pclass es num√©rica pero representa categor√≠as\n",
    "    cols_categoricas_onehot = ['sex', 'embarked'] # 'deck', 'embark_town', 'who', 'adult_male' tambi√©n son categ√≥ricas\n",
    "    \n",
    "    # Asegurarnos que las columnas existan en X\n",
    "    cols_numericas_existentes = [col for col in cols_numericas if col in X.columns]\n",
    "    cols_categoricas_onehot_existentes = [col for col in cols_categoricas_onehot if col in X.columns]\n",
    "    \n",
    "    print(f\"Columnas num√©ricas a procesar: {cols_numericas_existentes}\")\n",
    "    print(f\"Columnas categ√≥ricas (para OneHot) a procesar: {cols_categoricas_onehot_existentes}\")\n",
    "    \n",
    "    # Pipeline para transformaciones num√©ricas\n",
    "    pipeline_numerico = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')), # Imputar NaNs con la mediana\n",
    "        ('scaler', StandardScaler())                   # Escalar los datos\n",
    "    ])\n",
    "    \n",
    "    # Pipeline para transformaciones categ√≥ricas (One-Hot Encoding)\n",
    "    pipeline_categorico_onehot = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')), # Imputar NaNs con la moda\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)) # Convertir a dummies\n",
    "    ])\n",
    "    \n",
    "    # (Opcional) Podr√≠amos tener un pipeline para 'pclass' si quisi√©ramos tratarla como categ√≥rica\n",
    "    # pipeline_pclass = Pipeline(steps=[\n",
    "    #     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    #     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    # ])\n",
    "    # cols_pclass = ['pclass']\n",
    "    # Y luego quitar 'pclass' de cols_numericas_existentes.\n",
    "    # Por simplicidad, aqu√≠ la dejamos como num√©rica y la escalaremos.\n",
    "\n",
    "else:\n",
    "    print(\"El DataFrame X est√° vac√≠o. No se pueden definir pipelines.\")\n",
    "    pipeline_numerico = None\n",
    "    pipeline_categorico_onehot = None\n",
    "    cols_numericas_existentes = []\n",
    "    cols_categoricas_onehot_existentes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Construcci√≥n del `ColumnTransformer`\n",
    "\n",
    "El `ColumnTransformer` nos permite aplicar diferentes pipelines (o transformadores individuales) a diferentes subconjuntos de columnas del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer creado.\n"
     ]
    }
   ],
   "source": [
    "if not X.empty and pipeline_numerico and pipeline_categorico_onehot:\n",
    "    # Crear el ColumnTransformer\n",
    "    # Lista de tuplas: (nombre_transformador, pipeline_o_transformador, columnas_a_aplicar)\n",
    "    preprocesador = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', pipeline_numerico, cols_numericas_existentes),\n",
    "            ('cat_onehot', pipeline_categorico_onehot, cols_categoricas_onehot_existentes)\n",
    "            # ('cat_pclass', pipeline_pclass, cols_pclass) # Si hubi√©ramos definido pipeline_pclass\n",
    "        ],\n",
    "        remainder='drop' # 'drop' las columnas no especificadas. 'passthrough' las mantendr√≠a sin cambios.\n",
    "    )\n",
    "    print(\"ColumnTransformer creado.\")\n",
    "else:\n",
    "    print(\"No se pudo crear ColumnTransformer porque X o los pipelines no est√°n definidos.\")\n",
    "    preprocesador = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aplicaci√≥n del Pipeline de Preprocesamiento al Dataset\n",
    "\n",
    "Ahora, aplicamos el `preprocesador` (que es un `ColumnTransformer`) a nuestros datos `X`.\n",
    "El m√©todo `fit_transform()` ajustar√° los imputers, scalers y encoders a los datos y luego los transformar√°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset X preprocesado exitosamente.\n",
      "Forma del array X_preprocesado: (891, 10)\n",
      "\n",
      "Primeras 5 filas del array X_preprocesado:\n",
      "[[-0.56573646 -0.50244517  0.43279337 -0.47367361  0.82737724  0.\n",
      "   1.          0.          0.          1.        ]\n",
      " [ 0.66386103  0.78684529  0.43279337 -0.47367361 -1.56610693  1.\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.25833709 -0.48885426 -0.4745452  -0.47367361  0.82737724  1.\n",
      "   0.          0.          0.          1.        ]\n",
      " [ 0.4333115   0.42073024  0.43279337 -0.47367361 -1.56610693  1.\n",
      "   0.          0.          0.          1.        ]\n",
      " [ 0.4333115  -0.48633742 -0.4745452  -0.47367361  0.82737724  0.\n",
      "   1.          0.          0.          1.        ]]\n",
      "\n",
      "--- DataFrame X Preprocesado (Primeras Filas) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.565736</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.663861</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.258337</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.433312</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.433312</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age      fare     sibsp     parch    pclass  sex_female  sex_male  \\\n",
       "0 -0.565736 -0.502445  0.432793 -0.473674  0.827377         0.0       1.0   \n",
       "1  0.663861  0.786845  0.432793 -0.473674 -1.566107         1.0       0.0   \n",
       "2 -0.258337 -0.488854 -0.474545 -0.473674  0.827377         1.0       0.0   \n",
       "3  0.433312  0.420730  0.432793 -0.473674 -1.566107         1.0       0.0   \n",
       "4  0.433312 -0.486337 -0.474545 -0.473674  0.827377         0.0       1.0   \n",
       "\n",
       "   embarked_C  embarked_Q  embarked_S  \n",
       "0         0.0         0.0         1.0  \n",
       "1         1.0         0.0         0.0  \n",
       "2         0.0         0.0         1.0  \n",
       "3         0.0         0.0         1.0  \n",
       "4         0.0         0.0         1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if preprocesador and not X.empty:\n",
    "    try:\n",
    "        X_preprocesado_array = preprocesador.fit_transform(X)\n",
    "        print(\"\\nDataset X preprocesado exitosamente.\")\n",
    "        print(f\"Forma del array X_preprocesado: {X_preprocesado_array.shape}\")\n",
    "        \n",
    "        # Mostrar algunas filas del array resultante\n",
    "        print(\"\\nPrimeras 5 filas del array X_preprocesado:\")\n",
    "        print(X_preprocesado_array[:5])\n",
    "        \n",
    "        # (Opcional) Convertir de nuevo a DataFrame para inspecci√≥n\n",
    "        # Obtener los nombres de las caracter√≠sticas despu√©s de la transformaci√≥n\n",
    "        # Es un poco m√°s complejo obtener los nombres de caracter√≠sticas de OneHotEncoder dentro de ColumnTransformer\n",
    "        try:\n",
    "            nombres_features_numericas = cols_numericas_existentes\n",
    "            # Para OneHotEncoder, si est√° en el pipeline 'cat_onehot' y es el segundo paso ('onehot')\n",
    "            nombres_features_categoricas_onehot = preprocesador.named_transformers_['cat_onehot'].named_steps['onehot'].get_feature_names_out(cols_categoricas_onehot_existentes)\n",
    "            \n",
    "            nombres_features_finales = nombres_features_numericas + list(nombres_features_categoricas_onehot)\n",
    "            \n",
    "            X_preprocesado_df = pd.DataFrame(X_preprocesado_array, columns=nombres_features_finales, index=X.index)\n",
    "            print(\"\\n--- DataFrame X Preprocesado (Primeras Filas) ---\")\n",
    "            display(X_preprocesado_df.head())\n",
    "        except Exception as e_feature_names:\n",
    "            print(f\"Error al obtener nombres de caracter√≠sticas o crear DataFrame: {e_feature_names}\")\n",
    "            X_preprocesado_df = pd.DataFrame(X_preprocesado_array) # Sin nombres de columna\n",
    "            print(\"\\n--- DataFrame X Preprocesado (Primeras Filas, sin nombres de columna) ---\")\n",
    "            display(X_preprocesado_df.head())\n",
    "            \n",
    "    except Exception as e_transform:\n",
    "        print(f\"Error durante fit_transform del preprocesador: {e_transform}\")\n",
    "        X_preprocesado_array = None\n",
    "        X_preprocesado_df = None\n",
    "else:\n",
    "    print(\"Preprocesador o X no est√°n definidos. No se puede aplicar.\")\n",
    "    X_preprocesado_array = None\n",
    "    X_preprocesado_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentario sobre el Pipeline Completo:**\n",
    "Podr√≠amos haber envuelto nuestro `ColumnTransformer` en un `Pipeline` m√°s grande, especialmente si quisi√©ramos a√±adir un modelo al final:\n",
    "```python\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# pipeline_completo = Pipeline(steps=[\n",
    "#     ('preprocesador', preprocesador),\n",
    "#     ('clasificador', LogisticRegression()) \n",
    "# ])\n",
    "# pipeline_completo.fit(X_train, y_train)\n",
    "# predicciones = pipeline_completo.predict(X_test)\n",
    "```\n",
    "Esto ilustra c√≥mo el preprocesamiento se integra limpiamente en el flujo de trabajo de modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   age         891 non-null    float64\n",
      " 1   fare        891 non-null    float64\n",
      " 2   sibsp       891 non-null    float64\n",
      " 3   parch       891 non-null    float64\n",
      " 4   pclass      891 non-null    float64\n",
      " 5   sex_female  891 non-null    float64\n",
      " 6   sex_male    891 non-null    float64\n",
      " 7   embarked_C  891 non-null    float64\n",
      " 8   embarked_Q  891 non-null    float64\n",
      " 9   embarked_S  891 non-null    float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 69.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_preprocesado_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Resumen\n",
    "\n",
    "Los `Pipeline` y `ColumnTransformer` de Scikit-learn son herramientas incre√≠blemente √∫tiles para:\n",
    "* Organizar y simplificar tu c√≥digo de preprocesamiento.\n",
    "* Aplicar diferentes transformaciones a diferentes tipos de columnas de manera sistem√°tica.\n",
    "* Asegurar consistencia entre los datos de entrenamiento y prueba, previniendo la fuga de datos.\n",
    "* Facilitar la experimentaci√≥n con diferentes pasos de preprocesamiento y modelos.\n",
    "\n",
    "Dominar estas herramientas te permitir√° construir flujos de trabajo de Machine Learning mucho m√°s robustos y profesionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ejercicios Pr√°cticos üß©\n",
    "\n",
    "Utiliza el dataset de empleados (crudo, con nulos y diferentes tipos de datos) para construir un pipeline de preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 7.1: Pipeline de Preprocesamiento para Datos de Empleados\n",
    "\n",
    "**Dataset (versi√≥n cruda):**\n",
    "```python\n",
    "datos_empleados_crudo = {\n",
    "    'ID_Empleado': ['E01', 'E02', 'E03', 'E04', 'E05', 'E06', 'E02', 'E07', 'E08', 'E09', 'E10', 'E11'],\n",
    "    'Nombre': ['Carlos', 'Ana', 'Luis', 'Sofia', 'Pedro', 'Laura', 'Ana', 'David', 'Maria', 'Juan', np.nan, 'Elena'],\n",
    "    'Edad': [34, 28, 45, 30, np.nan, 25, 28, 50, 33, 200, 40, 29], # Nan, Outlier\n",
    "    'Departamento': ['Ventas', 'Marketing', 'TI', 'Ventas', 'TI', np.nan, 'Marketing', 'RRHH', 'Ventas', 'TI', 'Marketing', 'Ventas'], # Nan\n",
    "    'SalarioAnual': [60000.0, 75000.0, 90000.0, 62000.0, 85000.0, np.nan, 75000.0, 110000.0, 58000.0, 500000.0, 72000.0, np.nan], # Nan, Outlier\n",
    "    'AniosExperiencia': [5, 3, 10, 4, 7, 2, 3, 15, 6, 1, 8, np.nan] # Nan\n",
    "}\n",
    "df_empleados_crudo = pd.DataFrame(datos_empleados_crudo)\n",
    "```\n",
    "\n",
    "**Tareas:**\n",
    "1.  **Crea el DataFrame** `df_empleados_crudo`.\n",
    "2.  **Define las columnas:** Identifica las columnas num√©ricas (`Edad`, `SalarioAnual`, `AniosExperiencia`) y categ√≥ricas (`Departamento`). Las columnas `ID_Empleado` y `Nombre` pueden ser ignoradas o eliminadas por el `ColumnTransformer` (usando `remainder='drop'`).\n",
    "3.  **Crea los pipelines individuales:**\n",
    "    * `pipeline_numerico_emp`: Debe usar `SimpleImputer` (estrategia 'median') y `StandardScaler`.\n",
    "    * `pipeline_categorico_emp`: Debe usar `SimpleImputer` (estrategia 'most_frequent') y `OneHotEncoder` (`handle_unknown='ignore'`, `sparse_output=False`).\n",
    "4.  **Construye el `ColumnTransformer`** (`preprocesador_empleados`) para aplicar estos pipelines a las columnas correspondientes.\n",
    "5.  **Aplica el `preprocesador_empleados`** al DataFrame `df_empleados_crudo` (puedes excluir `ID_Empleado` y `Nombre` antes de pasarlo al `fit_transform` o dejar que `remainder='drop'` lo haga).\n",
    "6.  **Resultado:**\n",
    "    * Muestra la forma (shape) del array resultante.\n",
    "    * Muestra las primeras 5 filas del array resultante.\n",
    "    * (Opcional Avanzado) Intenta convertir el array resultante de nuevo a un DataFrame con nombres de columna apropiados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear DataFrame\n",
    "datos_empleados_crudo = {\n",
    "    'ID_Empleado': ['E01', 'E02', 'E03', 'E04', 'E05', 'E06', 'E02', 'E07', 'E08', 'E09', 'E10', 'E11'],\n",
    "    'Nombre': ['Carlos', 'Ana', 'Luis', 'Sofia', 'Pedro', 'Laura', 'Ana', 'David', 'Maria', 'Juan', np.nan, 'Elena'],\n",
    "    'Edad': [34, 28, 45, 30, np.nan, 25, 28, 50, 33, 200, 40, 29],\n",
    "    'Departamento': ['Ventas', 'Marketing', 'TI', 'Ventas', 'TI', np.nan, 'Marketing', 'RRHH', 'Ventas', 'TI', 'Marketing', 'Ventas'],\n",
    "    'SalarioAnual': [60000.0, 75000.0, 90000.0, 62000.0, 85000.0, np.nan, 75000.0, 110000.0, 58000.0, 500000.0, 72000.0, np.nan],\n",
    "    'AniosExperiencia': [5, 3, 10, 4, 7, 2, 3, 15, 6, 1, 8, np.nan]\n",
    "}\n",
    "df_empleados_crudo = pd.DataFrame(datos_empleados_crudo)\n",
    "print(\"--- DataFrame Original de Empleados (Ejercicio) ---\")\n",
    "display(df_empleados_crudo.head())\n",
    "df_empleados_crudo.info()\n",
    "\n",
    "# 2. Definir columnas\n",
    "cols_num_emp = ['Edad', 'SalarioAnual', 'AniosExperiencia']\n",
    "cols_cat_emp = ['Departamento']\n",
    "\n",
    "# 3. Crear pipelines individuales\n",
    "pipeline_numerico_emp = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "pipeline_categorico_emp = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# 4. Construir ColumnTransformer\n",
    "preprocesador_empleados = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', pipeline_numerico_emp, cols_num_emp),\n",
    "        ('cat', pipeline_categorico_emp, cols_cat_emp)\n",
    "    ],\n",
    "    remainder='drop' # Ignorar 'ID_Empleado' y 'Nombre'\n",
    ")\n",
    "\n",
    "# 5. Aplicar el preprocesador\n",
    "try:\n",
    "    X_empleados_procesado_array = preprocesador_empleados.fit_transform(df_empleados_crudo)\n",
    "    \n",
    "    # 6. Resultados\n",
    "    print(f\"\\nForma del array de empleados procesado: {X_empleados_procesado_array.shape}\")\n",
    "    print(\"\\nPrimeras 5 filas del array de empleados procesado:\")\n",
    "    print(X_empleados_procesado_array[:5])\n",
    "\n",
    "    # Opcional Avanzado: Convertir a DataFrame con nombres de columna\n",
    "    try:\n",
    "        nombres_num_emp = cols_num_emp\n",
    "        nombres_cat_emp_ohe = preprocesador_empleados.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(cols_cat_emp)\n",
    "        nombres_features_empleados = nombres_num_emp + list(nombres_cat_emp_ohe)\n",
    "        \n",
    "        df_empleados_procesado = pd.DataFrame(X_empleados_procesado_array, columns=nombres_features_empleados)\n",
    "        print(\"\\n--- DataFrame de Empleados Procesado (Primeras Filas) ---\")\n",
    "        display(df_empleados_procesado.head())\n",
    "        df_empleados_procesado.info()\n",
    "    except Exception as e_feat_names_emp:\n",
    "        print(f\"Error al obtener nombres de caracter√≠sticas para empleados: {e_feat_names_emp}\")\n",
    "        # Mostrar como array si falla la reconstrucci√≥n del DataFrame\n",
    "        df_empleados_procesado = pd.DataFrame(X_empleados_procesado_array)\n",
    "        display(df_empleados_procesado.head())\n",
    "        \n",
    "except Exception as e_pipeline_emp:\n",
    "    print(f\"Error al aplicar el pipeline de empleados: {e_pipeline_emp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
